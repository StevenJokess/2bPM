# 原则

关于人工智能的六点原则：

- 一是福祉原则。人工智能的发展应服务于人类共同福祉和利益，其设计与应用须遵循人类社会基本伦理道德，符合人类的尊严和权利。
- 二是安全原则。人工智能不得伤害人类，要保证人工智能系统的安全性、可适用性与可控性，保护个人隐私，防止数据泄露与滥用。保证人工智能算法的可追溯性与透明性，防止算法歧视。
- 三是共享原则。人工智能创造的经济繁荣应服务于全体人类。构建合理机制，使更多人受益于人工智能技术的发展、享受便利，避免数字鸿沟的出现。
- 四是和平原则。人工智能技术须用于和平目的，致力于提升透明度和建立信任措施，倡导和平利用人工智能，防止开展致命性自主武器军备竞赛。
- 五是法治原则。人工智能技术的运用，应符合《联合国宪章》的宗旨以及各国主权平等、和平解决争端、禁止使用武力、不干涉内政等现代国际法基本原则。
- 六是合作原则。世界各国应促进人工智能的技术交流和人才交流，在开放的环境下推动和规范技术的提升。这些原则可以作为讨论和制定人工智能国际规则的基础。

[1]: http://qjip.tsinghuajournals.com/article/2019/2096-1545/101393D-2019-1-102.shtml
